{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlwings as xw\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlDataName = '\\DissData [02]'\n",
    "dataFolder = r\"C:\\Users\\rfg\\OneDrive\\Desktop\\Dissertation ES30029\\data\"\n",
    "companyNamesRange = \"A1:A2009\"\n",
    "cellRng = \"A1:BYH288\"\n",
    "xlBook = xw.books(xlDataName[1:])\n",
    "sheetWhitelist = ['all_companies']\n",
    "fields = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = []\n",
    "for sheet in xlBook.sheets:\n",
    "    if sheet.name not in sheetWhitelist:\n",
    "        exec('{} = pd.DataFrame(xw.books(xlDataName[1:]).sheets(\"{}\").range(cellRng).value)'.format(sheet.name, sheet.name))\n",
    "        exec('fields.append({})'.format(sheet.name))\n",
    "        exec('{}.name = \"{}\"'.format(sheet.name, sheet.name))\n",
    "        \n",
    "\n",
    "\n",
    "# Clean up the dataframes to have correct cols and rows\n",
    "for field in fields:\n",
    "    companyNames = [str(i) for i in xlBook.sheets(\"all_companies\").range(companyNamesRange).value]\n",
    "    companyNames.insert(0, field.iloc[0][0])\n",
    "    field.columns = companyNames\n",
    "    field.index = field[field.columns[0]]\n",
    "    del field[field.columns[0]]\n",
    "    field.drop(field.index[0], inplace=True)\n",
    "    field.replace(\"NA\", np.nan, inplace=True)\n",
    "    field = field.apply(pd.to_numeric,errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove series which don't have data for a field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1562, 12)\n"
     ]
    }
   ],
   "source": [
    "errorCols = []\n",
    "for field in fields:\n",
    "    for col in field:\n",
    "        try:\n",
    "            if field[col].iloc[0][:4] == '$$ER': \n",
    "                errorCols.append(col)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "errorCols = list(dict.fromkeys(errorCols))\n",
    "\n",
    "for field in fields:\n",
    "    for col in errorCols:\n",
    "        del field[col]\n",
    "\n",
    "print(np.stack(fields, axis=-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame()\n",
    "\n",
    "r = p/p.shift(1)-1\n",
    "\n",
    "r.name = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n"
     ]
    }
   ],
   "source": [
    "ret_3m = pd.DataFrame()\n",
    "ret_6m = pd.DataFrame()\n",
    "ret_9m = pd.DataFrame()\n",
    "ret_12m = pd.DataFrame()\n",
    "ret_18m = pd.DataFrame()\n",
    "ret_24m = pd.DataFrame()\n",
    "ret_36m = pd.DataFrame()\n",
    "\n",
    "ret_3m = (1+r).rolling(window=3).apply(np.prod, raw=True)-1\n",
    "ret_6m = (1+r).rolling(window=6).apply(np.prod, raw=True)-1\n",
    "ret_9m = (1+r).rolling(window=9).apply(np.prod, raw=True)-1\n",
    "ret_12m = (1+r).rolling(window=12).apply(np.prod, raw=True)-1\n",
    "ret_18m = (1+r).rolling(window=18).apply(np.prod, raw=True)-1\n",
    "ret_24m = (1+r).rolling(window=24).apply(np.prod, raw=True)-1\n",
    "ret_36m = (1+r).rolling(window=36).apply(np.prod, raw=True)-1\n",
    "\n",
    "ret_3m.name = 'ret_3m'\n",
    "ret_6m.name = 'ret_6m'\n",
    "ret_9m.name = 'ret_9m'\n",
    "ret_12m.name = 'ret_12m'\n",
    "ret_18m.name = 'ret_18m'\n",
    "ret_24m.name = 'ret_24m'\n",
    "ret_36m.name = 'ret_36m'\n",
    "\n",
    "rollingReturns = [ret_3m, ret_6m, ret_9m, ret_12m, ret_18m, ret_24m, ret_36m]\n",
    "for i in rollingReturns:\n",
    "    print(i.values.shape)\n",
    "\n",
    "for i in rollingReturns:\n",
    "    fields.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n"
     ]
    }
   ],
   "source": [
    "map_3m = pd.DataFrame()\n",
    "map_6m = pd.DataFrame()\n",
    "map_9m = pd.DataFrame()\n",
    "map_12m = pd.DataFrame()\n",
    "map_18m = pd.DataFrame()\n",
    "map_24m = pd.DataFrame()\n",
    "map_36m = pd.DataFrame()\n",
    "\n",
    "# Calculate moving averages\n",
    "map_3m = p.rolling(window=3).mean()\n",
    "map_6m = p.rolling(window=6).mean()\n",
    "map_9m = p.rolling(window=9).mean()\n",
    "map_12m = p.rolling(window=12).mean()\n",
    "map_18m = p.rolling(window=18).mean()\n",
    "map_24m = p.rolling(window=24).mean()\n",
    "map_36m = p.rolling(window=36).mean()\n",
    "\n",
    "map_3m.name = 'map_3m'\n",
    "map_6m.name = 'map_6m'\n",
    "map_9m.name = 'map_9m'\n",
    "map_12m.name = 'map_12m'\n",
    "map_18m.name = 'map_18m'\n",
    "map_24m.name = 'map_24m'\n",
    "map_36m.name = 'map_36m'\n",
    "\n",
    "# Technical indicators (crosses of MAVs for example)\n",
    "\n",
    "movingAverages = [map_3m, map_6m, map_9m, map_12m, map_18m, map_24m, map_36m]\n",
    "for i in movingAverages:\n",
    "    print(i.values.shape)\n",
    "\n",
    "for i in movingAverages:\n",
    "    fields.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n",
      "(287, 1562)\n"
     ]
    }
   ],
   "source": [
    "std_3m = pd.DataFrame()\n",
    "std_6m = pd.DataFrame()\n",
    "std_9m = pd.DataFrame()\n",
    "std_12m = pd.DataFrame()\n",
    "std_18m = pd.DataFrame()\n",
    "std_24m = pd.DataFrame()\n",
    "std_36m = pd.DataFrame()\n",
    "\n",
    "std_3m = r.rolling(window=3).std() * (12 ** 0.5)\n",
    "std_6m = r.rolling(window=6).std() * (12 ** 0.5)\n",
    "std_9m = r.rolling(window=9).std() * (12 ** 0.5)\n",
    "std_12m = r.rolling(window=12).std() * (12 ** 0.5)\n",
    "std_18m = r.rolling(window=18).std() * (12 ** 0.5)\n",
    "std_24m = r.rolling(window=24).std() * (12 ** 0.5)\n",
    "std_36m = r.rolling(window=36).std() * (12 ** 0.5)\n",
    "\n",
    "std_3m.name = 'std_3m'\n",
    "std_6m.name = 'std_6m'\n",
    "std_9m.name = 'std_9m'\n",
    "std_12m.name = 'std_12m'\n",
    "std_18m.name = 'std_18m'\n",
    "std_24m.name = 'std_24m'\n",
    "std_36m.name = 'std_36m'\n",
    "\n",
    "volatilities = [std_3m, std_6m, std_9m, std_12m, std_18m, std_24m, std_36m]\n",
    "for i in volatilities:\n",
    "    print(i.values.shape)\n",
    "\n",
    "for i in volatilities:\n",
    "    fields.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Data Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save index and columns so that you can load up data with these\n",
    "# np.save(file=dataFolder+r'\\npData.npy', arr=np.stack(fields, axis=-1))\n",
    "# np.save(file=dataFolder+'\\index.npy', arr=p.index)\n",
    "# np.save(file=dataFolder+'\\columns.npy', arr=p.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rows and columns\n",
    "np.save(file=dataFolder+r'\\index.npy', arr=p.index)\n",
    "np.save(file=dataFolder+r'\\columns.npy', arr=p.columns)\n",
    "np.save(file=dataFolder+r'\\fields.npy', arr=[field.name for field in fields])\n",
    "\n",
    "\n",
    "for field in fields:\n",
    "    np.save(file=os.path.join(dataFolder, '{}.npy'.format(field.name)), arr=field)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
